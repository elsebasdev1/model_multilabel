{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "079ecfb4-0da8-4d23-9d77-6d7f98df7ce6",
   "metadata": {},
   "source": [
    "# 03_Model_Training.ipynb\n",
    "\n",
    "## Descripción\n",
    "En esta fase se implementa el ciclo de entrenamiento del modelo **ConvNeXt Base**. Se utiliza aprendizaje por transferencia (Transfer Learning) desde pesos de ImageNet, adaptando la arquitectura para clasificación Multi-Label (Sigmoid).\n",
    "\n",
    "## Características del Entrenamiento\n",
    "* **Arquitectura:** ConvNeXt Base (88M Parámetros).\n",
    "* **Optimizador:** AdamW (SOTA para Transformers/ConvNeXt).\n",
    "* **Regularización:** MixUp (Data Augmentation) + Label Smoothing implícito.\n",
    "* **Precisión:** Mixed Precision (FP16) para aceleración en GPU y optimización de VRAM.\n",
    "* **Tracking:** Integración completa con MLflow para registro de métricas y artefactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2294aa-6f06-4da9-8111-53b2a31c454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks, applications, optimizers, mixed_precision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Limpieza de memoria y sesion\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# Configuracion de Mixed Precision (FP16)\n",
    "# Acelera el entrenamiento y reduce el uso de memoria VRAM sin perder precision significativa\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Constantes de Entrenamiento\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8          # Ajustado para GPU de 6-8GB VRAM\n",
    "EPOCHS = 40\n",
    "NUM_CLASSES = 3\n",
    "MIXUP_ALPHA = 0.2       # Intensidad de la mezcla de imagenes\n",
    "\n",
    "# Reproducibilidad\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Verificacion de hardware\n",
    "print(f\"Politica de Precision: {policy.name}\")\n",
    "print(f\"GPUs Disponibles: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "\n",
    "# Estructura de Directorios\n",
    "BASE_DIR = '/tf/notebooks'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
    "LOGS_DIR = os.path.join(BASE_DIR, 'logs')\n",
    "OUTPUTS_DIR = os.path.join(BASE_DIR, 'outputs')\n",
    "\n",
    "for d in [MODELS_DIR, LOGS_DIR, OUTPUTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114cfe4-15f4-4777-b4bc-8d479c5326d9",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos Preprocesados\n",
    "Se cargan los tensores `.npy` generados en el paso anterior. Se realiza un casteo explícito a `float32` para garantizar la compatibilidad con las operaciones de la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71c8ae-134b-43f3-abb7-8e64b01c9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. CARGA DE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Cargando tensores desde disco...\")\n",
    "\n",
    "X_train = np.load(os.path.join(DATA_DIR, 'X_train.npy')).astype('float32')\n",
    "y_train = np.load(os.path.join(DATA_DIR, 'y_train.npy')).astype('float32')\n",
    "\n",
    "X_val   = np.load(os.path.join(DATA_DIR, 'X_val.npy')).astype('float32')\n",
    "y_val   = np.load(os.path.join(DATA_DIR, 'y_val.npy')).astype('float32')\n",
    "\n",
    "X_test  = np.load(os.path.join(DATA_DIR, 'X_test.npy')).astype('float32')\n",
    "y_test  = np.load(os.path.join(DATA_DIR, 'y_test.npy')).astype('float32')\n",
    "\n",
    "print(f\"Dimensiones de Entrenamiento: {X_train.shape}\")\n",
    "print(f\"Dimensiones de Validacion:    {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7706b805-ce3f-43dc-8ce4-7ba143f035e6",
   "metadata": {},
   "source": [
    "## 2. Pipeline de Entrada (tf.data)\n",
    "Se construye un pipeline de alto rendimiento utilizando `tf.data.Dataset`.\n",
    "* **Resize:** Escalado bicúbico a 224x224.\n",
    "* **MixUp:** Técnica de regularización que combina linealmente dos imágenes y sus etiquetas. Esto suaviza la superficie de decisión del modelo.\n",
    "* **Prefetch:** Carga asíncrona de datos para evitar cuellos de botella en la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf6743-1e43-4d85-ac57-779aa249682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. CONFIGURACION DEL PIPELINE (ETL)\n",
    "# ============================================================================\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    \"\"\"Redimensionado bicubico para mantener calidad visual\"\"\"\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE], method='bicubic')\n",
    "    return image, label\n",
    "\n",
    "def mixup(images, labels):\n",
    "    \"\"\"\n",
    "    Implementacion vectorial de MixUp.\n",
    "    Mezcla imagenes del mismo batch para regularizacion.\n",
    "    \"\"\"\n",
    "    alpha = MIXUP_ALPHA\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    \n",
    "    # Generacion de indices aleatorios para mezclar\n",
    "    indices = tf.random.shuffle(tf.range(batch_size))\n",
    "    images_2 = tf.gather(images, indices)\n",
    "    labels_2 = tf.gather(labels, indices)\n",
    "    \n",
    "    # Muestreo de la distribucion Beta\n",
    "    gamma = tf.random.gamma(shape=[batch_size], alpha=alpha)\n",
    "    beta = tf.random.gamma(shape=[batch_size], alpha=alpha)\n",
    "    lam = gamma / (gamma + beta)\n",
    "    lam = tf.reshape(lam, [-1, 1, 1, 1])\n",
    "    \n",
    "    # Mezcla lineal\n",
    "    images_mix = images * lam + images_2 * (1 - lam)\n",
    "    \n",
    "    # Mezcla de etiquetas\n",
    "    lam_labels = tf.reshape(lam, [-1, 1])\n",
    "    labels_mix = labels * lam_labels + labels_2 * (1 - lam_labels)\n",
    "    \n",
    "    return images_mix, labels_mix\n",
    "\n",
    "# Construccion de Datasets\n",
    "ds_train = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    .shuffle(1000)\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(mixup, num_parallel_calls=AUTO) # MixUp solo en entrenamiento\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "ds_val = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "ds_test = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "print(\"Pipeline de datos configurado y optimizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff2667-2bfc-4fb6-88b5-5a75401f9dd6",
   "metadata": {},
   "source": [
    "## 3. Arquitectura del Modelo\n",
    "Se instancia **ConvNeXt Base** con pesos pre-entrenados de ImageNet.\n",
    "* **Backbone:** ConvNeXt Base (sin la capa superior).\n",
    "* **Head (Clasificador):**\n",
    "    * Global Average Pooling.\n",
    "    * Layer Normalization (estándar para Transformers/ConvNeXt).\n",
    "    * Dense 1024 (GELU) + Dropout.\n",
    "    * **Salida:** 3 Neuronas con activación **Sigmoid** (Multi-label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c78fa1-3851-4fda-bef2-8f590609e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. DEFINICION DE LA ARQUITECTURA\n",
    "# ============================================================================\n",
    "\n",
    "def build_model():\n",
    "    # Backbone pre-entrenado\n",
    "    base_model = applications.ConvNeXtBase(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_preprocessing=True # Normalizacion interna integrada\n",
    "    )\n",
    "    \n",
    "    # Permitimos el fine-tuning completo\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base_model(inputs)\n",
    "    \n",
    "    # Cabecera de clasificacion personalizada\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    x = layers.Dense(1024, activation='gelu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Capa de salida (Sigmoid para independencia de clases)\n",
    "    # dtype='float32' es necesario para estabilidad numerica con Mixed Precision\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation='sigmoid', dtype='float32', name='predictions')(x)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"ConvNeXt_SOTA\")\n",
    "\n",
    "model = build_model()\n",
    "# model.summary() # Descomentar para ver arquitectura completa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc937ff-479c-40c6-be4c-4cfbac54bf75",
   "metadata": {},
   "source": [
    "## 4. Configuración del Entrenamiento\n",
    "* **Loss:** Binary Crossentropy (Estándar para multi-label).\n",
    "* **Métricas:** Binary Accuracy y AUC (Area Under Curve).\n",
    "* **Optimizador:** AdamW (Weight Decay desacoplado).\n",
    "* **Callbacks:**\n",
    "    * `ModelCheckpoint`: Guarda solo el mejor modelo.\n",
    "    * `ReduceLROnPlateau`: Reduce el learning rate si la validación se estanca.\n",
    "    * `EarlyStopping`: Detiene el entrenamiento si no hay mejora para evitar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c5df7-1730-4485-917f-9ae48f4b9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. COMPILACION Y CALLBACKS\n",
    "# ============================================================================\n",
    "\n",
    "# Optimizador AdamW (Recomendado para SOTA)\n",
    "optimizer = optimizers.AdamW(learning_rate=5e-5, weight_decay=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy', keras.metrics.AUC(name='auc', multi_label=True)]\n",
    ")\n",
    "\n",
    "# Configuracion de MLflow\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"admin\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"password1234\"\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\") # Ajustar URL segun entorno (http://mlflow:5000 interno)\n",
    "mlflow.set_experiment(\"ConvNeXt_Production_V1\")\n",
    "\n",
    "# Callbacks\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint_path = os.path.join(MODELS_DIR, f'best_model_{timestamp}.keras')\n",
    "\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        checkpoint_path, \n",
    "        monitor='val_binary_accuracy', \n",
    "        save_best_only=True, \n",
    "        mode='max', \n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.5, \n",
    "        patience=3, \n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_binary_accuracy', \n",
    "        patience=8, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.CSVLogger(os.path.join(LOGS_DIR, f'training_log_{timestamp}.csv'))\n",
    "]\n",
    "\n",
    "print(f\"Modelo configurado. Checkpoint: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08559368-ba2f-4126-b676-8dc58180c281",
   "metadata": {},
   "source": [
    "## 5. Ejecución del Entrenamiento\n",
    "Inicio del ciclo de entrenamiento con registro automático en MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf25b2-cd58-49c1-867c-bc9cd97eb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. EJECUCION (TRAINING LOOP)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Iniciando entrenamiento...\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Train_{timestamp}\") as run:\n",
    "    # Registro de hiperparametros\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"ConvNeXt Base\",\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": 5e-5\n",
    "    })\n",
    "    \n",
    "    # Entrenamiento\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "print(\"Entrenamiento finalizado exitosamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe806b1-cf4b-443c-ab18-2c9ce56d7e24",
   "metadata": {},
   "source": [
    "## 6. Evaluación de Calidad del Modelo\n",
    "Se genera el reporte de clasificación detallado y la matriz de confusión para detectar sesgos entre clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bab44-0288-4d1c-936e-d57c765971f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. EVALUACION Y METRICAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Generando predicciones sobre Test Set...\")\n",
    "# Prediccion sobre todo el set de prueba\n",
    "y_pred_probs = model.predict(ds_test)\n",
    "\n",
    "# Convertir probabilidades a clases (Threshold 0.5 para logica binaria/multilabel)\n",
    "# Para la matriz de confusion de CIFAR (que es single label), usamos argmax\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1) # y_test venia en one-hot\n",
    "\n",
    "# 1. Reporte de Clasificacion\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REPORTE DE CLASIFICACION\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=CLASS_NAMES))\n",
    "\n",
    "# 2. Matriz de Confusion\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title(f'Matriz de Confusión (Accuracy Global: {history.history[\"val_binary_accuracy\"][-1]*100:.2f}%)')\n",
    "plt.savefig(os.path.join(OUTPUTS_DIR, 'confusion_matrix.png'))\n",
    "plt.show()\n",
    "\n",
    "# 3. Grafico de Entrenamiento\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['binary_accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_binary_accuracy'], label='Val Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(OUTPUTS_DIR, 'training_curves.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c4827-02ab-45d7-99ce-087f9499d43f",
   "metadata": {},
   "source": [
    "## 7. Protocolo de Exportación a Producción (CPU-Safe)\n",
    "\n",
    "Esta etapa implementa un procedimiento de exportación seguro diseñado para entornos de producción. Se realizan las siguientes operaciones críticas:\n",
    "\n",
    "1.  **Aislamiento de Hardware (CPU Force):** Se fuerza al entorno a utilizar la CPU (`CUDA_VISIBLE_DEVICES=\"-1\"`). Esto evita errores de fragmentación de memoria VRAM (OOM) al cargar simultáneamente el modelo de entrenamiento y la instancia de inferencia.\n",
    "2.  **Stripping del Optimizador:** Se elimina el estado del optimizador (AdamW). Estos pesos son necesarios solo para el entrenamiento (retropropagación) pero inútiles para la inferencia. Eliminarlos reduce el tamaño del archivo final entre un 50% y un 70%.\n",
    "3.  **Sanity Check:** Se realiza una carga de prueba y una predicción con datos sintéticos (dummy) para garantizar la integridad del archivo binario antes del despliegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a523cd-9b3f-4b2a-9c57-a5b46270c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7. EXPORTACION SEGURA Y OPTIMIZACION\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURACION DE ENTORNO\n",
    "# Forzamos el uso de CPU para liberar la GPU y evitar conflictos de memoria (OOM)\n",
    "# durante la manipulacion final del modelo.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"INICIANDO PROTOCOLO DE EXPORTACION (MODO CPU)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Directorios\n",
    "BASE_DIR = '/tf/notebooks'\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
    "EXPORT_DIR = os.path.join(BASE_DIR, 'production_models')\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. Identificacion del mejor checkpoint\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nBuscando ultimo modelo entrenado...\")\n",
    "list_of_models = glob.glob(os.path.join(MODELS_DIR, 'best_model_*.keras'))\n",
    "\n",
    "if not list_of_models:\n",
    "    raise FileNotFoundError(\"No se encontraron modelos en la carpeta models/\")\n",
    "\n",
    "# Seleccionamos el mas reciente por fecha de modificacion\n",
    "latest_model_path = max(list_of_models, key=os.path.getctime)\n",
    "initial_size = os.path.getsize(latest_model_path) / (1024 * 1024) # MB\n",
    "\n",
    "print(f\"Modelo seleccionado: {os.path.basename(latest_model_path)}\")\n",
    "print(f\"Peso original (con optimizador): {initial_size:.2f} MB\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2. Carga y Limpieza\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"Cargando modelo en memoria RAM (System Memory)...\")\n",
    "model = keras.models.load_model(latest_model_path)\n",
    "\n",
    "export_path = os.path.join(EXPORT_DIR, 'model_convnext_base_final.keras')\n",
    "\n",
    "print(f\"Exportando version optimizada a: {export_path}\")\n",
    "\n",
    "# include_optimizer=False: Elimina los pesos de AdamW (reduccion ~60-70% size)\n",
    "model.save(export_path, include_optimizer=False)\n",
    "\n",
    "# Calculo de metricas de optimizacion\n",
    "final_size = os.path.getsize(export_path) / (1024 * 1024)\n",
    "reduction = (1 - (final_size / initial_size)) * 100\n",
    "\n",
    "print(\"\\nRESULTADOS DE LA OPTIMIZACION:\")\n",
    "print(f\"Peso Inicial: {initial_size:.2f} MB\")\n",
    "print(f\"Peso Final:   {final_size:.2f} MB\")\n",
    "print(f\"Reduccion:    {reduction:.1f}%\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3. Verificacion de Integridad (Sanity Check)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nValidando integridad del archivo exportado...\")\n",
    "\n",
    "# Liberar memoria del modelo pesado\n",
    "del model\n",
    "keras.backend.clear_session()\n",
    "\n",
    "try:\n",
    "    # Recarga del modelo ligero\n",
    "    model_light = keras.models.load_model(export_path)\n",
    "    print(\"El modelo se cargo correctamente.\")\n",
    "\n",
    "    # Inferencia de prueba con tensor de ceros\n",
    "    dummy_input = tf.random.uniform((1, 224, 224, 3))\n",
    "    print(\"Ejecutando prediccion de prueba...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pred = model_light.predict(dummy_input, verbose=0)\n",
    "    duration = (time.time() - start_time) * 1000\n",
    "    \n",
    "    print(f\"Prediccion exitosa. Shape de salida: {pred.shape}\")\n",
    "    print(f\"Tiempo de inferencia (Cold Start): {duration:.2f} ms\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR CRITICO durante la validacion: {e}\")\n",
    "    raise e\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PROCESO FINALIZADO: Modelo listo para despliegue en API.\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
