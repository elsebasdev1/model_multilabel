{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ea32f6-4a91-4bc8-9b54-8373b97e5e95",
   "metadata": {},
   "source": [
    "# 04_Domain_Adaptation_FineTuning.ipynb\n",
    "\n",
    "## Descripción General\n",
    "Este cuaderno aborda el desafío de la **Brecha de Dominio (Domain Gap)** existente entre el dataset de entrenamiento académico (CIFAR-10, 32x32px) y las imágenes del mundo real (HD).\n",
    "\n",
    "Aunque el modelo base ha alcanzado métricas de SOTA en el entorno controlado, su rendimiento puede degradarse ante texturas de alta frecuencia y artefactos de compresión presentes en fotografías reales.\n",
    "\n",
    "## Estrategia de Adaptación\n",
    "1.  **Ingesta de Datos HD:** Carga de un dataset curado de imágenes de alta resolución (`dataset_hd`).\n",
    "2.  **Alineación de Tensores:** Verificación y corrección automática del orden de las clases (One-Hot Mapping) para garantizar la consistencia con la topología del modelo base.\n",
    "3.  **Fine-Tuning Conservador:** Entrenamiento con una tasa de aprendizaje reducida (`1e-5`) para ajustar los pesos de las capas profundas sin destruir la extracción de características aprendida previamente (Catastrophic Forgetting).\n",
    "4.  **Exportación a Producción:** Generación del binario final optimizado para inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f407305-c1f4-4a8c-add7-2404ce35d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "# 1. Gestion de Recursos\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# 2. Configuracion del Entorno\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8  # Batch reducido para estabilidad durante el ajuste fino\n",
    "EPOCHS_FT = 15  # Ciclo corto de epocas\n",
    "LEARNING_RATE = 1e-5 # Tasa de aprendizaje de magnitud reducida\n",
    "\n",
    "# Directorios de Trabajo\n",
    "BASE_DIR = '/tf/notebooks'\n",
    "HD_DATA_DIR = os.path.join(BASE_DIR, 'dataset_hd')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
    "PROD_DIR = os.path.join(BASE_DIR, 'production_models')\n",
    "OUTPUTS_DIR = os.path.join(BASE_DIR, 'outputs')\n",
    "\n",
    "# Orden estricto de clases esperado por el modelo base (CIFAR-10 Mapping)\n",
    "# Indice 0: Dog, Indice 1: Automobile, Indice 2: Bird\n",
    "MODEL_CLASS_ORDER = ['dog', 'automobile', 'bird']\n",
    "\n",
    "print(\"Entorno de Fine-Tuning inicializado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e9cfd-981d-41fa-a471-028e5f4e6912",
   "metadata": {},
   "source": [
    "## 1. Carga y Sincronización de Datos HD\n",
    "La carga de datos desde directorios (`image_dataset_from_directory`) asigna índices basados en el orden alfabético de las carpetas. Esto suele diferir del orden lógico definido manualmente en etapas anteriores.\n",
    "\n",
    "Se implementa una capa de preprocesamiento lógico que detecta la discrepancia y reordena los tensores de etiquetas (One-Hot) dinámicamente para evitar la corrupción del conocimiento del modelo (ej. evitar que aprenda que \"Auto\" ahora es \"Perro\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e6abd-b7a7-4097-bfed-5c9b560c1f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. CARGA DE DATASET HD Y ALINEACION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Cargando dataset de Adaptacion (HD)...\")\n",
    "\n",
    "# Carga inicial (Orden alfabetico predeterminado)\n",
    "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    HD_DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    HD_DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Deteccion del orden actual en disco\n",
    "detected_order = train_ds_raw.class_names\n",
    "print(f\"\\nOrden detectado en disco: {detected_order}\")\n",
    "print(f\"Orden requerido por modelo: {MODEL_CLASS_ORDER}\")\n",
    "\n",
    "# Logica de reordenamiento de etiquetas\n",
    "if detected_order != MODEL_CLASS_ORDER:\n",
    "    print(\"ALERTA: Discrepancia de orden detectada. Aplicando correccion de tensores...\")\n",
    "    \n",
    "    # Calculo de indices de permutacion\n",
    "    # Mapea donde esta cada clase requerida en la lista detectada\n",
    "    perm_indices = [detected_order.index(cls) for cls in MODEL_CLASS_ORDER]\n",
    "    \n",
    "    def fix_label_order(images, labels):\n",
    "        \"\"\"Reordena las columnas del vector One-Hot segun la permutacion calculada\"\"\"\n",
    "        return images, tf.gather(labels, perm_indices, axis=1)\n",
    "    \n",
    "    # Aplicacion al pipeline\n",
    "    train_ds = train_ds_raw.map(fix_label_order)\n",
    "    val_ds = val_ds_raw.map(fix_label_order)\n",
    "    print(\"Correccion aplicada exitosamente.\")\n",
    "else:\n",
    "    train_ds = train_ds_raw\n",
    "    val_ds = val_ds_raw\n",
    "    print(\"El orden coincide. No se requieren correcciones.\")\n",
    "\n",
    "# Preprocesamiento final (Normalizacion ConvNeXt)\n",
    "from tensorflow.keras.applications.convnext import preprocess_input\n",
    "\n",
    "def preprocess_input_layer(images, labels):\n",
    "    return preprocess_input(images), labels\n",
    "\n",
    "train_ds = train_ds.map(preprocess_input_layer)\n",
    "val_ds = val_ds.map(preprocess_input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b8bbc-80a9-4a0c-8546-9cc20d6650ef",
   "metadata": {},
   "source": [
    "## 2. Evaluación de Línea Base (Baseline)\n",
    "Antes de modificar los pesos del modelo, se evalúa su rendimiento actual sobre el dataset HD. Esto establece un punto de partida para cuantificar la mejora obtenida mediante la adaptación de dominio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9561bf7-5bac-4b81-a83c-2e4b6b894cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. CARGA DEL MODELO BASE Y BENCHMARK\n",
    "# ============================================================================\n",
    "\n",
    "# Identificacion del ultimo checkpoint\n",
    "list_of_models = glob.glob(os.path.join(MODELS_DIR, 'best_model_*.keras'))\n",
    "if not list_of_models:\n",
    "    raise FileNotFoundError(\"No se encontraron modelos base en models/\")\n",
    "\n",
    "latest_model_path = max(list_of_models, key=os.path.getctime)\n",
    "print(f\"Cargando modelo base: {os.path.basename(latest_model_path)}\")\n",
    "\n",
    "model = keras.models.load_model(latest_model_path)\n",
    "\n",
    "# Evaluacion\n",
    "print(\"\\nEjecutando evaluacion de linea base (Pre-Tuning)...\")\n",
    "baseline_results = model.evaluate(val_ds, verbose=0)\n",
    "print(f\"Accuracy Inicial (HD): {baseline_results[1]*100:.2f}%\")\n",
    "print(f\"Loss Inicial (HD):     {baseline_results[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2236e-db52-4420-9132-7394801d630b",
   "metadata": {},
   "source": [
    "## 3. Ejecución de Fine-Tuning\n",
    "Se procede al re-entrenamiento del modelo.\n",
    "* **Optimizador:** Adam.\n",
    "* **Learning Rate:** `1e-5`. Este valor es crítico; un valor más alto podría destruir los patrones aprendidos en CIFAR-10.\n",
    "* **Capas:** Se mantienen todas las capas entrenables (*Unfrozen*) para permitir una adaptación global de los mapas de características a la nueva resolución y texturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973aa2f-9001-4974-af5b-05bf3d92e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. FINE-TUNING (ADAPTACION DE DOMINIO)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"Iniciando Fine-Tuning ({EPOCHS_FT} epocas, LR={LEARNING_RATE})...\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_FT,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluacion Post-Tuning\n",
    "final_results = model.evaluate(val_ds, verbose=0)\n",
    "improvement = (final_results[1] - baseline_results[1]) * 100\n",
    "\n",
    "print(\"\\nRESULTADOS DE LA ADAPTACION:\")\n",
    "print(f\"Accuracy Final (HD): {final_results[1]*100:.2f}%\")\n",
    "print(f\"Mejora Absoluta:     +{improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989db1d-a061-4da8-9873-c11640c27982",
   "metadata": {},
   "source": [
    "## 4. Validación de Calidad\n",
    "Generación de métricas detalladas utilizando el conjunto de validación HD para asegurar que el modelo no ha introducido sesgos hacia ninguna clase específica durante la adaptación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b833420-2b06-4cd2-97a8-e3f31c601529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. ANALISIS DE RESULTADOS\n",
    "# ============================================================================\n",
    "\n",
    "# Extraccion de etiquetas y predicciones\n",
    "val_images = []\n",
    "val_labels = []\n",
    "\n",
    "for img, label in val_ds:\n",
    "    val_images.append(img.numpy())\n",
    "    val_labels.append(label.numpy())\n",
    "\n",
    "X_val_np = np.vstack(val_images)\n",
    "y_val_np = np.vstack(val_labels)\n",
    "\n",
    "# Inferencia\n",
    "y_pred_probs = model.predict(X_val_np, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(y_val_np, axis=1)\n",
    "\n",
    "# Matriz de Confusion\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=MODEL_CLASS_ORDER,\n",
    "            yticklabels=MODEL_CLASS_ORDER)\n",
    "plt.title('Matriz de Confusión: Modelo Adaptado HD')\n",
    "plt.ylabel('Etiqueta Real')\n",
    "plt.xlabel('Predicción')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUTS_DIR, 'confusion_matrix_hd.png'))\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nReporte de Clasificacion:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=MODEL_CLASS_ORDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df268927-b397-4ebc-82df-f3151d6db7c4",
   "metadata": {},
   "source": [
    "## 5. Despliegue\n",
    "Exportación del modelo final adaptado (`model_production_hd.keras`). Este artefacto reemplazará al modelo anterior en el entorno de producción (FastAPI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09f6f0-6d93-4dff-befa-0ea45143eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. EXPORTACION A PRODUCCION\n",
    "# ============================================================================\n",
    "\n",
    "os.makedirs(PROD_DIR, exist_ok=True)\n",
    "final_path = os.path.join(PROD_DIR, 'model_production_hd.keras')\n",
    "\n",
    "print(f\"Guardando modelo optimizado en: {final_path}\")\n",
    "\n",
    "# Guardado sin optimizador para reducir tamano (~50%)\n",
    "model.save(final_path, include_optimizer=False)\n",
    "\n",
    "print(\"Proceso completado. Modelo listo para integracion en API.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
