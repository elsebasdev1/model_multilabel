# ğŸ‘ï¸ SOTA Multi-Label Visual Analysis System

![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.17-orange?style=for-the-badge&logo=tensorflow)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker)
![Status](https://img.shields.io/badge/Status-Production_Ready-success?style=for-the-badge)

> **Un sistema de visiÃ³n artificial de alto rendimiento capaz de detectar mÃºltiples objetos simultÃ¡neamente en entornos no controlados, utilizando arquitecturas ConvNeXt Base y estrategias de AdaptaciÃ³n de Dominio.**

---

## ğŸ“¸ Demo & Interfaz

El sistema cuenta con una interfaz minimalista y profesional desarrollada con **TailwindCSS**, diseÃ±ada para la inferencia en tiempo real.

![Dashboard Principal](assets/demo_dashboard.png)
*(AquÃ­ va captura del Front completo mostrando el input y los resultados vacÃ­os)*

### ğŸ” DetecciÃ³n Inteligente (Tiling Strategy)
El sistema no solo mira la imagen completa. Aplica una estrategia de **"Smart Tiling"** (6 vistas simultÃ¡neas) para detectar objetos pequeÃ±os u ocultos, como un loro en la ventana de un auto.

![Resultado Multi-Label](assets/result_multilabel.png)
*(AquÃ­ va captura del resultado "Automobile + Bird" mostrando las barras de progreso)*

---

## ğŸš€ CaracterÃ­sticas Clave

* **ğŸ§  Arquitectura SOTA:** Basado en **ConvNeXt Base** (88M parÃ¡metros), pre-entrenado en ImageNet y ajustado especÃ­ficamente para nuestro dominio.
* **ğŸ”„ Motor Dual (Dual-Engine):**
    * **Modo Standard:** Entrenado en CIFAR-10 (Accuracy 99.8%) para benchmarks acadÃ©micos.
    * **Modo HD (Real World):** Ajustado mediante *Fine-Tuning* para fotografÃ­as de alta resoluciÃ³n, superando el problema del "Domain Gap".
* **ğŸ° Inference Tiling:** Procesa 6 recortes estratÃ©gicos (Centro + 4 Esquinas + Original) en paralelo para maximizar el Recall.
* **ğŸšï¸ Umbral DinÃ¡mico:** Ajuste automÃ¡tico de sensibilidad (30% vs 50%) dependiendo del modelo seleccionado para reducir Falsos Negativos en contextos complejos.
* **ğŸ³ Dockerized:** Despliegue inmediato con un solo comando.

---

## ğŸ› ï¸ Arquitectura del Proyecto

El proyecto sigue una metodologÃ­a rigurosa de Data Science dividida en 4 fases (Cuadernos):

### 1. AnÃ¡lisis & Estrategia
DefiniciÃ³n del problema Multi-Label. SelecciÃ³n de **CIFAR-10** como dataset base y **Sigmoid** como funciÃ³n de activaciÃ³n para permitir probabilidades independientes (e.g., 99% Perro, 99% Auto).

### 2. IngenierÃ­a de Datos (ETL)
Pipeline de extracciÃ³n y transformaciÃ³n.
* Filtrado de clases irrelevantes.
* Upscaling bicÃºbico a **224x224**.
* Persistencia en formato binario `.npy` para optimizar I/O.

### 3. Entrenamiento (Transfer Learning)
Entrenamiento del modelo base utilizando tÃ©cnicas de regularizaciÃ³n avanzadas:
* **MixUp Augmentation:** Para suavizar la frontera de decisiÃ³n.
* **Mixed Precision (FP16):** Para optimizar el uso de VRAM.
* **Resultado:** 99.87% Accuracy en Test Set.

![Curvas de Entrenamiento](assets/training_curves.png)
*(AquÃ­ va captura de las grÃ¡ficas de Loss/Accuracy del cuaderno 03)*

### 4. AdaptaciÃ³n de Dominio (The "Real World" Fix)
ResoluciÃ³n del problema de **"Catastrophic Forgetting"** en imÃ¡genes HD.
* Ingesta de dataset curado HD.
* CorrecciÃ³n automÃ¡tica de alineaciÃ³n de etiquetas (Label Re-ordering).
* Fine-Tuning con Learning Rate reducido (`1e-5`).
* **Mejora:** Del 83% al **94.4%** en imÃ¡genes reales.

---

## ğŸ’» InstalaciÃ³n y Uso

### Prerrequisitos
* Docker & Docker Compose
* NVIDIA GPU (Opcional, el sistema tiene modo CPU-Safe)

### Despliegue RÃ¡pido
Clona el repositorio y levanta el contenedor:

```bash
git clone [https://github.com/tu-usuario/multilabel-vision-system.git](https://github.com/tu-usuario/multilabel-vision-system.git)
cd multilabel-vision-system

# Construir y levantar
docker-compose up --build

Accede a la interfaz web en: http://localhost:8000
```
## ğŸ“‚ Estructura del Repositorio

â”œâ”€â”€ app.py                 # Backend FastAPI (LÃ³gica Dual + Tiling)
â”œâ”€â”€ Dockerfile             # ConfiguraciÃ³n de entorno Python 3.11 Slim
â”œâ”€â”€ requirements.txt       # Dependencias (TensorFlow, Pillow, FastAPI)
â”œâ”€â”€ index.html             # Frontend (HTML5 + TailwindCSS)
â”œâ”€â”€ notebooks/             # Jupyter Notebooks (El cerebro del proyecto)
â”‚   â”œâ”€â”€ 01_Analysis.ipynb
â”‚   â”œâ”€â”€ 02_Preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_Training_SOTA.ipynb
â”‚   â””â”€â”€ 04_Domain_Adaptation.ipynb
â””â”€â”€ models/                # Pesos de los modelos (.keras)

## ğŸ“Š MÃ©tricas de Rendimiento
Modelo,Dataset,Accuracy,Inferencia (Avg)
Standard,CIFAR-10 (Test),99.87%,~150ms
HD Fine-Tuned,Real World HD,94.44%,~3000ms (con Tiling)
