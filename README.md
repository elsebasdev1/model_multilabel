# üëÅÔ∏è SOTA Multi-Label Visual Analysis System

![Python](https://img.shields.io/badge/Python-3.16-blue?style=for-the-badge&logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.17-orange?style=for-the-badge&logo=tensorflow)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker)
![Status](https://img.shields.io/badge/Status-Production_Ready-success?style=for-the-badge)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-blue?style=for-the-badge&logo=mlflow)


## RESUMEN (ABSTRACT)
**Problema:** Los modelos de clasificaci√≥n de im√°genes entrenados en datasets acad√©micos de baja resoluci√≥n (como CIFAR-10) sufren una degradaci√≥n severa de rendimiento ("Domain Gap") cuando se aplican a im√°genes del mundo real de alta definici√≥n.

**Propuesta:** Se presenta un m√©todo en tres fases que utiliza una arquitectura **ConvNeXt Base**. Se implementa una estrategia de *Transfer Learning* inicial, seguida de una t√©cnica de *Domain Adaptation* (Fine-Tuning) y un despliegue con estrategia de "Smart Tiling" para maximizar la detecci√≥n de objetos peque√±os.

**Dataset:** Se utiliza CIFAR-10 para el aprendizaje de representaciones base y un dataset propietario (HD Real World) para la adaptaci√≥n.

**Resultados:** El m√©todo alcanza un 99.87% de Accuracy en el dominio acad√©mico y mejora del 83% al 94.44% en el dominio real tras la adaptaci√≥n.

---

## M√âTODO PROPUESTO
La arquitectura de la soluci√≥n se ha dise√±ado siguiendo un pipeline de ciencia de datos estricto, dividido en tres fases macro: Ingenier√≠a de Datos, Modelado SOTA y Adaptaci√≥n de Dominio.

### Diagrama del M√©todo (Mermaid)

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'fontSize':'14px'}}}%%
graph LR
    subgraph FILA1[" "]
        direction LR
        A1["<b>Fase 1: Ingenier√≠a de Datos</b><br/><br/>‚ë† Ingesta Datos CIFAR-10<br/>‚ë° EDA: An√°lisis de Clases<br/>‚ë¢ Upscaling 32‚Üí224px<br/>‚ë£ Normalizaci√≥n ConvNeXt"]
        A2["<b>Fase 2: Modelado SOTA</b><br/><br/>‚ë† Arq: ConvNeXt Base<br/>‚ë° MixUp Augmentation<br/>‚ë¢ Optimizador: AdamW<br/>‚ë£ Modelo Base 99%"]
    end
    
    subgraph FILA2[" "]
        direction LR
        B1["<b>Fase 3: Adaptaci√≥n Dominio</b><br/><br/>‚ë† Ingesta Dataset HD Real<br/>‚ë° Correcci√≥n Etiquetas<br/>‚ë¢ Fine-Tuning LR=1e-5<br/>‚ë£ Validaci√≥n MLflow"]
        B2["<b>Fase 4: Servicio & App</b><br/><br/>‚ë† Interfaz PWA/C√°mara<br/>‚ë° Smart Tiling 6-Vistas<br/>‚ë¢ Motor Dual Std/HD<br/>‚ë£ Despliegue Docker"]
    end
    
    A1 --> A2
    A2 --> B1
    B1 --> B2
    
    FILA1 ~~~ FILA2
    
    style A1 fill:#FFFACD,stroke:#000,stroke-width:2px,text-align:left
    style A2 fill:#FFFACD,stroke:#000,stroke-width:2px,text-align:left
    style B1 fill:#FFFACD,stroke:#000,stroke-width:2px,text-align:left
    style B2 fill:#FFFACD,stroke:#000,stroke-width:2px,text-align:left
    style FILA1 fill:none,stroke:none
    style FILA2 fill:none,stroke:none
```

### Descripci√≥n de Algoritmos por Fase

- **Phase 1 - Data Engineering & Preparation:** En esta fase, se desarrollan cinco pasos cr√≠ticos para la preparaci√≥n y transformaci√≥n de los datos.
    * **Step 1. Data Ingestion:** Se realiza la carga distribuida del dataset acad√©mico (CIFAR-10) y la ingesta del dataset propietario de alta definici√≥n (HD Real World).
    * **Step 2. EDA & Cleaning:** An√°lisis estad√≠stico de la distribuci√≥n de clases para identificar desbalanceos y filtrado de muestras corruptas.
    * **Step 3. Bicubic Upscaling:** Cada imagen de baja resoluci√≥n ($32 \times 32$) es transformada mediante interpolaci√≥n bic√∫bica a $224 \times 224$ p√≠xeles para satisfacer los requisitos espaciales de la arquitectura ConvNeXt.
    * **Step 4. Normalization:** Se aplica la estandarizaci√≥n de canales (media y desviaci√≥n est√°ndar de ImageNet) y la transformaci√≥n de etiquetas a formato *One-Hot Encoding*.
    * **Step 5. Serialization:** Persistencia de los tensores procesados en formato binario `.npy` para optimizar la velocidad de I/O durante el entrenamiento.

- **Phase 2 - SOTA Model Training:** En esta fase se construye y entrena el modelo base para el aprendizaje de representaciones robustas.
    * **Step 1. ConvNeXt Architecture Setup:** Instanciaci√≥n del backbone **ConvNeXt Base** (88M par√°metros) pre-entrenado en ImageNet, modificando la capa densa final para nuestro problema multi-label.
    * **Step 2. MixUp Augmentation:** Implementaci√≥n de la t√©cnica de regularizaci√≥n *MixUp*, que genera muestras de entrenamiento sint√©ticas mediante la combinaci√≥n lineal convexa de pares de im√°genes y sus etiquetas ($x' = \lambda x_i + (1-\lambda)x_j$) con $\alpha=0.2$.
    * **Step 3. Optimization Strategy:** Configuraci√≥n del optimizador **AdamW** junto con *Mixed Precision Training* (FP16) para maximizar la eficiencia computacional en GPU.

- **Phase 3 - Domain Adaptation (Fine-Tuning):** En esta fase se resuelve el problema de "Domain Gap" para adaptar el modelo al mundo real.
    * **Step 1. Tensor Alignment:** Algoritmo de correcci√≥n autom√°tica que reordena los vectores de etiquetas del dataset HD para coincidir con la topolog√≠a del modelo pre-entrenado.
    * **Step 2. Continuous Training:** Ejecuci√≥n de un ciclo de *Fine-Tuning* con una tasa de aprendizaje microsc√≥pica ($1e-5$) y capas descongeladas, permitiendo al modelo ajustar sus pesos a texturas de alta resoluci√≥n sin olvidar el conocimiento previo (*Catastrophic Forgetting Mitigation*).
    * **Step 3. MLflow Tracking:** Monitoreo en tiempo real de m√©tricas de validaci√≥n (AUC, Accuracy, Loss) para asegurar la convergencia estable.

- **Phase 4 - Production & Serving:** Implementaci√≥n de la l√≥gica de inferencia para el usuario final.
    * **Step 1. Smart Tiling Algorithm:** Estrategia de pre-procesamiento que recorta la imagen de entrada en 6 vistas estrat√©gicas (Esquinas + Centro + Original) para mejorar el *Recall* en objetos peque√±os.
    * **Step 2. Dual Engine Selection:** L√≥gica de control que selecciona din√°micamente entre el modelo Standard y el modelo HD, ajustando el umbral de decisi√≥n (0.30 vs 0.50) seg√∫n el contexto de la imagen.

---

## üì∏ Demo & Interfaz

El sistema cuenta con una interfaz minimalista y profesional desarrollada con **TailwindCSS**, dise√±ada para la inferencia en tiempo real.

<img width="2511" height="1343" alt="Screenshot 2026-02-01 122139" src="https://github.com/user-attachments/assets/6f982791-6b76-439f-9851-f5aa0ee95448" />

### üîç Detecci√≥n Inteligente (Tiling Strategy)
El sistema no solo mira la imagen completa. Aplica una estrategia de **"Smart Tiling"** (6 vistas simult√°neas) para detectar objetos peque√±os u ocultos.

<img width="1815" height="1167" alt="Screenshot 2026-02-01 122407" src="https://github.com/user-attachments/assets/890b12f8-31c3-4074-a66d-98769df496d6" />

---

## üöÄ Caracter√≠sticas Clave

* **üß† Arquitectura SOTA:** Basado en **ConvNeXt Base** (88M par√°metros), pre-entrenado en ImageNet y ajustado espec√≠ficamente para nuestro dominio.
* **üîÑ Motor Dual (Dual-Engine):**
    * **Modo Standard:** Entrenado en CIFAR-10 (Accuracy 99.8%) para benchmarks acad√©micos.
    * **Modo HD (Real World):** Ajustado mediante *Fine-Tuning* para fotograf√≠as de alta resoluci√≥n, superando el problema del "Domain Gap".
* **üç∞ Inference Tiling:** Procesa 6 recortes estrat√©gicos (Centro + 4 Esquinas + Original) en paralelo para maximizar el Recall.
* **üéöÔ∏è Umbral Din√°mico:** Ajuste autom√°tico de sensibilidad (30% vs 50%) dependiendo del modelo seleccionado para reducir Falsos Negativos en contextos complejos.
* **üê≥ Dockerized:** Despliegue inmediato con un solo comando.

---

## MLOps & Experiment Tracking (MLflow)

Para garantizar la reproducibilidad cient√≠fica y el monitoreo en tiempo real, se integr√≥ el ciclo de entrenamiento con MLflow. Esto permiti√≥ auditar la evoluci√≥n de los gradientes y detectar convergencia temprana.

### Tablero de m√©tricas en tiempo real
<img width="1866" height="696" alt="Screenshot_20260202_141826" src="https://github.com/user-attachments/assets/764fb2f4-c5c1-4570-9431-1bd69ccdcb02" />

## An√°lisis de las M√©tricas

### Convergencia Robusta
El val_loss cae r√°pidamente y se estabiliza cerca de 0.01, confirmando que no hay overfitting degradante.

### Efecto MixUp
Se observa que el train_accuracy es inferior al val_accuracy. Esto es un comportamiento esperado y deseable cuando se utiliza MixUp Augmentation: el modelo entrena con im√°genes mezcladas para forzar una generalizaci√≥n perfecta en los datos de validaci√≥n.

### AUC SOTA
La m√©trica val_auc se mantiene constante cerca de 1.0, lo que valida la capacidad del modelo para separar las clases con un umbral de decisi√≥n limpio.

---

## üõ†Ô∏è Arquitectura del Proyecto

El proyecto sigue una metodolog√≠a rigurosa de Data Science dividida en 4 fases (Cuadernos):

### 1. An√°lisis & Estrategia
Definici√≥n del problema Multi-Label. Selecci√≥n de **CIFAR-10** como dataset base y **Sigmoid** como funci√≥n de activaci√≥n para permitir probabilidades independientes (e.g., 99% Perro, 99% Auto).

### 2. Ingenier√≠a de Datos (ETL)
Pipeline de extracci√≥n y transformaci√≥n.
* Filtrado de clases irrelevantes.
* Upscaling bic√∫bico a **224x224**.
* Persistencia en formato binario `.npy` para optimizar I/O.

### 3. Entrenamiento (Transfer Learning)
Entrenamiento del modelo base utilizando t√©cnicas de regularizaci√≥n avanzadas:
* **MixUp Augmentation:** Para suavizar la frontera de decisi√≥n.
* **Mixed Precision (FP16):** Para optimizar el uso de VRAM.
* **Resultado:** 99.87% Accuracy en Test Set.

### 4. Adaptaci√≥n de Dominio (The "Real World" Fix)
Resoluci√≥n del problema de **"Catastrophic Forgetting"** en im√°genes HD.
* Ingesta de dataset curado HD.
* Correcci√≥n autom√°tica de alineaci√≥n de etiquetas (Label Re-ordering).
* Fine-Tuning con Learning Rate reducido (`1e-5`).
* **Mejora:** Del 83% al **94.4%** en im√°genes reales.
<img width="1438" height="553" alt="Screenshot_20260202_141033" src="https://github.com/user-attachments/assets/c1d9c860-1873-4a8a-b6f7-d88b09a84eab" />

## Resultados Comparativos (Dataset Real-World)

| M√©trica           | Standard (CIFAR-10) | HD (Fine-Tuned) | Diferencia |
|-------------------|--------------------|----------------|------------|
| Accuracy Global   | 33.33%             | 100.00%        | +66.67%    |
| F1 dog            | 50.00%             | 100.00%        | +50.00%    |
| F1 automobile     | 0.00%              | 0.00%          | +0.00%     |
| F1 bird           | 0.00%              | 0.00%          | +0.00%     |

---

## üíª Instalaci√≥n y Uso

### Prerrequisitos
* Docker & Docker Compose
* NVIDIA GPU (Opcional, el sistema tiene modo CPU-Safe)

### Despliegue R√°pido
Clona el repositorio y levanta el contenedor:

```bash
git clone [https://github.com/elsebasdev1/model_multilabel.git](https://github.com/elsebasdev1/model_multilabel.git)
cd model_multilabel

# Construir y levantar
docker-compose up --build

Accede a la interfaz web en: http://localhost:8000
```
## üìÇ Estructura del Repositorio
```
‚îú‚îÄ‚îÄ app.py                 # Backend FastAPI (L√≥gica Dual + Tiling)
‚îú‚îÄ‚îÄ Dockerfile             # Configuraci√≥n de entorno Python 3.11 Slim
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias (TensorFlow, Pillow, FastAPI)
‚îú‚îÄ‚îÄ index.html             # Frontend (HTML5 + TailwindCSS)
‚îú‚îÄ‚îÄ notebooks/             # Jupyter Notebooks (El cerebro del proyecto)
‚îÇ   ‚îú‚îÄ‚îÄ 01_Analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_Preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_Training_SOTA.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_Domain_Adaptation.ipynb
‚îî‚îÄ‚îÄ models/                # Pesos de los modelos (.keras)
```
## 5. CONCLUSIONES

Detectar m√∫ltiples objetos simult√°neamente en entornos no controlados es un gran desaf√≠o; puede verse afectado dr√°sticamente por la variabilidad en la resoluci√≥n, oclusiones parciales y las diferencias de dominio entre los datos de entrenamiento y los del mundo real. Uno de los principales obst√°culos en la investigaci√≥n aplicada de visi√≥n artificial es la brecha de rendimiento ("Domain Gap") que existe al trasladar modelos entrenados en datasets acad√©micos a producci√≥n.

Por esta raz√≥n, hemos proporcionado un caso de estudio, una arquitectura de cuatro fases y un m√©todo de *Deep Learning* basado en **ConvNeXt** y **Adaptaci√≥n de Dominio** para el procesamiento y an√°lisis de im√°genes HD, enfocado en la detecci√≥n de clases espec√≠ficas (Dog, Automobile, Bird).

Hemos proporcionado un conjunto de experimentos utilizando un dataset p√∫blico (CIFAR-10) y un dataset propietario de alta definici√≥n, utilizando medidas de calidad est√°ndar (Accuracy, F1-Score) y la discusi√≥n de m√©todos de *Transfer Learning*. Los resultados demuestran que, mediante t√©cnicas de *Fine-Tuning* y *Smart Tiling*, es posible elevar la precisi√≥n en el mundo real del 33% al 94.4%.

Hemos proporcionado un conjunto de cuadernos (Notebooks) para la reproducibilidad de los experimentos y para el desarrollo de nuevos m√©todos a partir de este caso de estudio, cubriendo desde la ingenier√≠a de datos hasta el despliegue en producci√≥n.

Como trabajo futuro, consideramos, adem√°s de un enfoque inductivo, explorar un enfoque h√≠brido que a√±ada inteligencia artificial deductiva apoyada en el modelado de conocimiento experto (reglas de contexto), con el fin de mejorar significativamente los resultados en escenarios con alta oclusi√≥n. Asimismo, pretendemos experimentar con t√©cnicas modernas como *Ensemble Learning* combinando arquitecturas como Swin Transformer y EfficientNet para robustecer la inferencia.

---

## 6. REFERENCIAS

1.  **Krizhevsky, Alex, and Geoffrey Hinton.** "Learning multiple layers of features from tiny images". (2009): 7. [Dataset CIFAR-10]. Recuperado de: https://www.cs.toronto.edu/~kriz/cifar.html
2.  **Liu, Zhuang, et al.** "A ConvNet for the 2020s". *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*. (2022). DOI: https://doi.org/10.48550/arXiv.2201.03545
3.  **Zhang, Hongyi, et al.** "mixup: Beyond Empirical Risk Minimization". *International Conference on Learning Representations (ICLR)*. (2018). DOI: https://doi.org/10.48550/arXiv.1710.09412
4.  **Loshchilov, Ilya, and Frank Hutter.** "Decoupled Weight Decay Regularization" (AdamW). *International Conference on Learning Representations*. (2019). DOI: https://doi.org/10.48550/arXiv.1711.05101
