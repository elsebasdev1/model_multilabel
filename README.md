# ğŸ‘ï¸ SOTA Multi-Label Visual Analysis System

![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.17-orange?style=for-the-badge&logo=tensorflow)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker)
![Status](https://img.shields.io/badge/Status-Production_Ready-success?style=for-the-badge)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-blue?style=for-the-badge&logo=mlflow)


> **Un sistema de visiÃ³n artificial de alto rendimiento capaz de detectar mÃºltiples objetos simultÃ¡neamente en entornos no controlados, utilizando arquitecturas ConvNeXt Base y estrategias de AdaptaciÃ³n de Dominio.**

---

## ğŸ“¸ Demo & Interfaz

El sistema cuenta con una interfaz minimalista y profesional desarrollada con **TailwindCSS**, diseÃ±ada para la inferencia en tiempo real.

<img width="2511" height="1343" alt="Screenshot 2026-02-01 122139" src="https://github.com/user-attachments/assets/6f982791-6b76-439f-9851-f5aa0ee95448" />

### ğŸ” DetecciÃ³n Inteligente (Tiling Strategy)
El sistema no solo mira la imagen completa. Aplica una estrategia de **"Smart Tiling"** (6 vistas simultÃ¡neas) para detectar objetos pequeÃ±os u ocultos.

<img width="1815" height="1167" alt="Screenshot 2026-02-01 122407" src="https://github.com/user-attachments/assets/890b12f8-31c3-4074-a66d-98769df496d6" />

---

## ğŸš€ CaracterÃ­sticas Clave

* **ğŸ§  Arquitectura SOTA:** Basado en **ConvNeXt Base** (88M parÃ¡metros), pre-entrenado en ImageNet y ajustado especÃ­ficamente para nuestro dominio.
* **ğŸ”„ Motor Dual (Dual-Engine):**
    * **Modo Standard:** Entrenado en CIFAR-10 (Accuracy 99.8%) para benchmarks acadÃ©micos.
    * **Modo HD (Real World):** Ajustado mediante *Fine-Tuning* para fotografÃ­as de alta resoluciÃ³n, superando el problema del "Domain Gap".
* **ğŸ° Inference Tiling:** Procesa 6 recortes estratÃ©gicos (Centro + 4 Esquinas + Original) en paralelo para maximizar el Recall.
* **ğŸšï¸ Umbral DinÃ¡mico:** Ajuste automÃ¡tico de sensibilidad (30% vs 50%) dependiendo del modelo seleccionado para reducir Falsos Negativos en contextos complejos.
* **ğŸ³ Dockerized:** Despliegue inmediato con un solo comando.

---

## MLOps & Experiment Tracking (MLflow)

Para garantizar la reproducibilidad cientÃ­fica y el monitoreo en tiempo real, se integrÃ³ el ciclo de entrenamiento con MLflow. Esto permitiÃ³ auditar la evoluciÃ³n de los gradientes y detectar convergencia temprana.

### Tablero de mÃ©tricas en tiempo real
<img width="1866" height="696" alt="Screenshot_20260202_141826" src="https://github.com/user-attachments/assets/764fb2f4-c5c1-4570-9431-1bd69ccdcb02" />

## AnÃ¡lisis de las MÃ©tricas

### Convergencia Robusta
El val_loss cae rÃ¡pidamente y se estabiliza cerca de 0.01, confirmando que no hay overfitting degradante.

### Efecto MixUp
Se observa que el train_accuracy es inferior al val_accuracy. Esto es un comportamiento esperado y deseable cuando se utiliza MixUp Augmentation: el modelo entrena con imÃ¡genes mezcladas para forzar una generalizaciÃ³n perfecta en los datos de validaciÃ³n.

### AUC SOTA
La mÃ©trica val_auc se mantiene constante cerca de 1.0, lo que valida la capacidad del modelo para separar las clases con un umbral de decisiÃ³n limpio.

---

## ğŸ› ï¸ Arquitectura del Proyecto

El proyecto sigue una metodologÃ­a rigurosa de Data Science dividida en 4 fases (Cuadernos):

### 1. AnÃ¡lisis & Estrategia
DefiniciÃ³n del problema Multi-Label. SelecciÃ³n de **CIFAR-10** como dataset base y **Sigmoid** como funciÃ³n de activaciÃ³n para permitir probabilidades independientes (e.g., 99% Perro, 99% Auto).

### 2. IngenierÃ­a de Datos (ETL)
Pipeline de extracciÃ³n y transformaciÃ³n.
* Filtrado de clases irrelevantes.
* Upscaling bicÃºbico a **224x224**.
* Persistencia en formato binario `.npy` para optimizar I/O.

### 3. Entrenamiento (Transfer Learning)
Entrenamiento del modelo base utilizando tÃ©cnicas de regularizaciÃ³n avanzadas:
* **MixUp Augmentation:** Para suavizar la frontera de decisiÃ³n.
* **Mixed Precision (FP16):** Para optimizar el uso de VRAM.
* **Resultado:** 99.87% Accuracy en Test Set.

### 4. AdaptaciÃ³n de Dominio (The "Real World" Fix)
ResoluciÃ³n del problema de **"Catastrophic Forgetting"** en imÃ¡genes HD.
* Ingesta de dataset curado HD.
* CorrecciÃ³n automÃ¡tica de alineaciÃ³n de etiquetas (Label Re-ordering).
* Fine-Tuning con Learning Rate reducido (`1e-5`).
* **Mejora:** Del 83% al **94.4%** en imÃ¡genes reales.
<img width="1438" height="553" alt="Screenshot_20260202_141033" src="https://github.com/user-attachments/assets/c1d9c860-1873-4a8a-b6f7-d88b09a84eab" />

## Resultados Comparativos (Dataset Real-World)

| MÃ©trica           | Standard (CIFAR-10) | HD (Fine-Tuned) | Diferencia |
|-------------------|--------------------|----------------|------------|
| Accuracy Global   | 33.33%             | 100.00%        | +66.67%    |
| F1 dog            | 50.00%             | 100.00%        | +50.00%    |
| F1 automobile     | 0.00%              | 0.00%          | +0.00%     |
| F1 bird           | 0.00%              | 0.00%          | +0.00%     |

---

## ğŸ’» InstalaciÃ³n y Uso

### Prerrequisitos
* Docker & Docker Compose
* NVIDIA GPU (Opcional, el sistema tiene modo CPU-Safe)

### Despliegue RÃ¡pido
Clona el repositorio y levanta el contenedor:

```bash
git clone [https://github.com/elsebasdev1/model_multilabel.git](https://github.com/elsebasdev1/model_multilabel.git)
cd model_multilabel

# Construir y levantar
docker-compose up --build

Accede a la interfaz web en: http://localhost:8000
```
## ğŸ“‚ Estructura del Repositorio
```
â”œâ”€â”€ app.py                 # Backend FastAPI (LÃ³gica Dual + Tiling)
â”œâ”€â”€ Dockerfile             # ConfiguraciÃ³n de entorno Python 3.11 Slim
â”œâ”€â”€ requirements.txt       # Dependencias (TensorFlow, Pillow, FastAPI)
â”œâ”€â”€ index.html             # Frontend (HTML5 + TailwindCSS)
â”œâ”€â”€ notebooks/             # Jupyter Notebooks (El cerebro del proyecto)
â”‚   â”œâ”€â”€ 01_Analysis.ipynb
â”‚   â”œâ”€â”€ 02_Preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_Training_SOTA.ipynb
â”‚   â””â”€â”€ 04_Domain_Adaptation.ipynb
â””â”€â”€ models/                # Pesos de los modelos (.keras)
```
## ğŸ“Š MÃ©tricas de Rendimiento
| Modelo         | Dataset         | Accuracy | Inferencia (Avg)      |
|:--------------|:----------------|:--------:|----------------------:|
| Standard      | CIFAR-10 (Test) | 99.87%   | ~5000 ms               |
| HD Fine-Tuned | Real World HD   | 94.44%   | ~5500 ms              |

