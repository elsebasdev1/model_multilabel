# üëÅÔ∏è SOTA Multi-Label Visual Analysis System

![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.17-orange?style=for-the-badge&logo=tensorflow)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker)
![Status](https://img.shields.io/badge/Status-Production_Ready-success?style=for-the-badge)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-blue?style=for-the-badge&logo=mlflow)


## 1. RESUMEN (ABSTRACT)
**Problema:** Los modelos de clasificaci√≥n de im√°genes entrenados en datasets acad√©micos de baja resoluci√≥n (como CIFAR-10) sufren una degradaci√≥n severa de rendimiento ("Domain Gap") cuando se aplican a im√°genes del mundo real de alta definici√≥n.
**Propuesta:** Se presenta un m√©todo en tres fases que utiliza una arquitectura **ConvNeXt Base**. Se implementa una estrategia de *Transfer Learning* inicial, seguida de una t√©cnica de *Domain Adaptation* (Fine-Tuning) y un despliegue con estrategia de "Smart Tiling" para maximizar la detecci√≥n de objetos peque√±os.
**Dataset:** Se utiliza CIFAR-10 para el aprendizaje de representaciones base y un dataset propietario (HD Real World) para la adaptaci√≥n.
**Resultados:** El m√©todo alcanza un 99.87% de Accuracy en el dominio acad√©mico y mejora del 83% al 94.44% en el dominio real tras la adaptaci√≥n.

---

## 2. M√âTODO PROPUESTO
La arquitectura de la soluci√≥n se ha dise√±ado siguiendo un pipeline de ciencia de datos estricto, dividido en tres fases macro: Ingenier√≠a de Datos, Modelado SOTA y Adaptaci√≥n de Dominio.

### Diagrama del M√©todo (Mermaid)

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'fontSize':'14px'}}}%%
graph LR
    subgraph FILA1[" "]
        direction LR
        A1["<b>Fase 1: Ingenier√≠a de Datos</b><br/><br/>‚ë† Ingesta Datos CIFAR-10<br/>‚ë° EDA: An√°lisis de Clases<br/>‚ë¢ Upscaling 32‚Üí224px<br/>‚ë£ Normalizaci√≥n ConvNeXt"]
        A2["<b>Fase 2: Modelado SOTA</b><br/><br/>‚ë† Arq: ConvNeXt Base<br/>‚ë° MixUp Augmentation<br/>‚ë¢ Optimizador: AdamW<br/>‚ë£ Modelo Base 99%"]
    end
    
    subgraph FILA2[" "]
        direction LR
        B1["<b>Fase 3: Adaptaci√≥n Dominio</b><br/><br/>‚ë† Ingesta Dataset HD Real<br/>‚ë° Correcci√≥n Etiquetas<br/>‚ë¢ Fine-Tuning LR=1e-5<br/>‚ë£ Validaci√≥n MLflow"]
        B2["<b>Fase 4: Servicio & App</b><br/><br/>‚ë† Interfaz PWA/C√°mara<br/>‚ë° Smart Tiling 6-Vistas<br/>‚ë¢ Motor Dual Std/HD<br/>‚ë£ Despliegue Docker"]
    end
    
    A1 --> A2
    A2 --> B1
    B1 --> B2
    
    FILA1 ~~~ FILA2
    
    style A1 fill:#FFFACD,stroke:#000,stroke-width:2px,text-align:left
    style A2 fill:#FFFACD,stroke:#000,stroke-width:2px,text-align:left
    style B1 fill:#FFFACD,stroke:#000,stroke-width:2px,text-align:left
    style B2 fill:#FFFACD,stroke:#000,stroke-width:2px,text-align:left
    style FILA1 fill:none,stroke:none
    style FILA2 fill:none,stroke:none
```

---

## üì∏ Demo & Interfaz

El sistema cuenta con una interfaz minimalista y profesional desarrollada con **TailwindCSS**, dise√±ada para la inferencia en tiempo real.

<img width="2511" height="1343" alt="Screenshot 2026-02-01 122139" src="https://github.com/user-attachments/assets/6f982791-6b76-439f-9851-f5aa0ee95448" />

### üîç Detecci√≥n Inteligente (Tiling Strategy)
El sistema no solo mira la imagen completa. Aplica una estrategia de **"Smart Tiling"** (6 vistas simult√°neas) para detectar objetos peque√±os u ocultos.

<img width="1815" height="1167" alt="Screenshot 2026-02-01 122407" src="https://github.com/user-attachments/assets/890b12f8-31c3-4074-a66d-98769df496d6" />

---

## üöÄ Caracter√≠sticas Clave

* **üß† Arquitectura SOTA:** Basado en **ConvNeXt Base** (88M par√°metros), pre-entrenado en ImageNet y ajustado espec√≠ficamente para nuestro dominio.
* **üîÑ Motor Dual (Dual-Engine):**
    * **Modo Standard:** Entrenado en CIFAR-10 (Accuracy 99.8%) para benchmarks acad√©micos.
    * **Modo HD (Real World):** Ajustado mediante *Fine-Tuning* para fotograf√≠as de alta resoluci√≥n, superando el problema del "Domain Gap".
* **üç∞ Inference Tiling:** Procesa 6 recortes estrat√©gicos (Centro + 4 Esquinas + Original) en paralelo para maximizar el Recall.
* **üéöÔ∏è Umbral Din√°mico:** Ajuste autom√°tico de sensibilidad (30% vs 50%) dependiendo del modelo seleccionado para reducir Falsos Negativos en contextos complejos.
* **üê≥ Dockerized:** Despliegue inmediato con un solo comando.

---

## MLOps & Experiment Tracking (MLflow)

Para garantizar la reproducibilidad cient√≠fica y el monitoreo en tiempo real, se integr√≥ el ciclo de entrenamiento con MLflow. Esto permiti√≥ auditar la evoluci√≥n de los gradientes y detectar convergencia temprana.

### Tablero de m√©tricas en tiempo real
<img width="1866" height="696" alt="Screenshot_20260202_141826" src="https://github.com/user-attachments/assets/764fb2f4-c5c1-4570-9431-1bd69ccdcb02" />

## An√°lisis de las M√©tricas

### Convergencia Robusta
El val_loss cae r√°pidamente y se estabiliza cerca de 0.01, confirmando que no hay overfitting degradante.

### Efecto MixUp
Se observa que el train_accuracy es inferior al val_accuracy. Esto es un comportamiento esperado y deseable cuando se utiliza MixUp Augmentation: el modelo entrena con im√°genes mezcladas para forzar una generalizaci√≥n perfecta en los datos de validaci√≥n.

### AUC SOTA
La m√©trica val_auc se mantiene constante cerca de 1.0, lo que valida la capacidad del modelo para separar las clases con un umbral de decisi√≥n limpio.

---

## üõ†Ô∏è Arquitectura del Proyecto

El proyecto sigue una metodolog√≠a rigurosa de Data Science dividida en 4 fases (Cuadernos):

### 1. An√°lisis & Estrategia
Definici√≥n del problema Multi-Label. Selecci√≥n de **CIFAR-10** como dataset base y **Sigmoid** como funci√≥n de activaci√≥n para permitir probabilidades independientes (e.g., 99% Perro, 99% Auto).

### 2. Ingenier√≠a de Datos (ETL)
Pipeline de extracci√≥n y transformaci√≥n.
* Filtrado de clases irrelevantes.
* Upscaling bic√∫bico a **224x224**.
* Persistencia en formato binario `.npy` para optimizar I/O.

### 3. Entrenamiento (Transfer Learning)
Entrenamiento del modelo base utilizando t√©cnicas de regularizaci√≥n avanzadas:
* **MixUp Augmentation:** Para suavizar la frontera de decisi√≥n.
* **Mixed Precision (FP16):** Para optimizar el uso de VRAM.
* **Resultado:** 99.87% Accuracy en Test Set.

### 4. Adaptaci√≥n de Dominio (The "Real World" Fix)
Resoluci√≥n del problema de **"Catastrophic Forgetting"** en im√°genes HD.
* Ingesta de dataset curado HD.
* Correcci√≥n autom√°tica de alineaci√≥n de etiquetas (Label Re-ordering).
* Fine-Tuning con Learning Rate reducido (`1e-5`).
* **Mejora:** Del 83% al **94.4%** en im√°genes reales.
<img width="1438" height="553" alt="Screenshot_20260202_141033" src="https://github.com/user-attachments/assets/c1d9c860-1873-4a8a-b6f7-d88b09a84eab" />

## Resultados Comparativos (Dataset Real-World)

| M√©trica           | Standard (CIFAR-10) | HD (Fine-Tuned) | Diferencia |
|-------------------|--------------------|----------------|------------|
| Accuracy Global   | 33.33%             | 100.00%        | +66.67%    |
| F1 dog            | 50.00%             | 100.00%        | +50.00%    |
| F1 automobile     | 0.00%              | 0.00%          | +0.00%     |
| F1 bird           | 0.00%              | 0.00%          | +0.00%     |

---

## üíª Instalaci√≥n y Uso

### Prerrequisitos
* Docker & Docker Compose
* NVIDIA GPU (Opcional, el sistema tiene modo CPU-Safe)

### Despliegue R√°pido
Clona el repositorio y levanta el contenedor:

```bash
git clone [https://github.com/elsebasdev1/model_multilabel.git](https://github.com/elsebasdev1/model_multilabel.git)
cd model_multilabel

# Construir y levantar
docker-compose up --build

Accede a la interfaz web en: http://localhost:8000
```
## üìÇ Estructura del Repositorio
```
‚îú‚îÄ‚îÄ app.py                 # Backend FastAPI (L√≥gica Dual + Tiling)
‚îú‚îÄ‚îÄ Dockerfile             # Configuraci√≥n de entorno Python 3.11 Slim
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias (TensorFlow, Pillow, FastAPI)
‚îú‚îÄ‚îÄ index.html             # Frontend (HTML5 + TailwindCSS)
‚îú‚îÄ‚îÄ notebooks/             # Jupyter Notebooks (El cerebro del proyecto)
‚îÇ   ‚îú‚îÄ‚îÄ 01_Analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_Preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_Training_SOTA.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_Domain_Adaptation.ipynb
‚îî‚îÄ‚îÄ models/                # Pesos de los modelos (.keras)
```
